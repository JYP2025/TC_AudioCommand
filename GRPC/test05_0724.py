import os
import pyaudio
from six.moves import queue
from google.cloud import speech
import requests
import time
import threading
import re

# âœ… Google ì¸ì¦ í‚¤ ê²½ë¡œ ì„¤ì •
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "C:/Users/JYP/Documents/GitHub/TC_AudioCommand/GRPC/my-key01.json"

# ğŸ“¡ TriCaster ì„¤ì •
TRICASTER_IP = "172.30.20.6"
INPUT_MAP = {
    "1": "input1", "2": "input2", "3": "input3", "4": "input4",
    "5": "input5", "6": "input6", "7": "input7", "8": "input8",
    "p1": "input9", "p2": "input10",
    "m1": "input13", "m2": "input14",
}

# ğŸ§ ì˜¤ë””ì˜¤ ì„¤ì •
RATE = 16000
CHUNK = int(RATE / 10)


class MicrophoneStream:
    def __init__(self, rate, chunk):
        self._rate = rate
        self._chunk = chunk
        self._buff = queue.Queue()
        self.closed = True

    def __enter__(self):
        self._audio_interface = pyaudio.PyAudio()
        self._audio_stream = self._audio_interface.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=self._rate,
            input=True,
            frames_per_buffer=self._chunk,
            stream_callback=self._fill_buffer,
        )
        self.closed = False
        return self

    def __exit__(self, type, value, traceback):
        self._audio_stream.stop_stream()
        self._audio_stream.close()
        self.closed = True
        self._buff.put(None)
        self._audio_interface.terminate()

    def _fill_buffer(self, in_data, frame_count, time_info, status_flags):
        self._buff.put(in_data)
        return None, pyaudio.paContinue

    def generator(self):
        while not self.closed:
            chunk = self._buff.get()
            if chunk is None:
                continue
            yield chunk

# ğŸ§  ë°œìŒ ë³´ì • í…Œì´ë¸”
phonetic_map = {
    "one": "1", "two": "2", "too": "2", "to": "2", "three": "3", "tree": "3",
    "four": "4", "for": "4", "fo": "4", "five": "5", "six": "6", "seven": "7",
    "eight": "8", "nine": "9", "ten": "10",
    "mone": "m1", "m-one": "m1", "m1": "m1", "mtwo": "m2", "m2": "m2",
    "pone": "p1", "p1": "p1", "ptwo": "p2", "p2": "p2",
    "test": "test", "cut": "cut", "mix": "mix"
}

last_command = ""
last_command_time = 0
command_timeout = 1.5
last_preview_key = None
test_completed = False

def normalize_command(text):
    compact = text.replace(" ", "").lower()
    compact = re.sub(r'(\b\w+)\1+', r'\1', compact)
    compact = re.sub(r'(\w)\1+', r'\1', compact)
    return phonetic_map.get(compact, compact)

def remove_consecutive_duplicates(words):
    result = []
    prev = None
    for word in words:
        if word != prev:
            result.append(word)
            prev = word
    return result

# ğŸ“¡ TriCaster ì œì–´

def preview_input(input_key):
    global last_preview_key
    input_name = INPUT_MAP.get(input_key)
    if input_name:
        last_preview_key = input_key
        requests.get(f"http://{TRICASTER_IP}/v1/shortcut", params={"name": "main_b_row_named_input", "value": input_name})
        print(f"ğŸ¯ PREVIEW SET â†’ {input_key} ({input_name})", flush=True)

def cut():
    requests.get(f"http://{TRICASTER_IP}/v1/shortcut", params={"name": "main_take"})
    print("âœ‚ï¸ CUT (Preview â†’ Program)", flush=True)

def mix():
    requests.get(f"http://{TRICASTER_IP}/v1/shortcut", params={"name": "main_auto"})
    print("ğŸï¸ MIX (Preview â†’ Program)", flush=True)

def direct_cut(input_key):
    preview_input(input_key)
    cut()
    print(f"âš¡ DIRECT CUT â†’ {input_key} ({INPUT_MAP.get(input_key)})", flush=True)

# ğŸ¤ ìŒì„± ì¸ì‹ ë£¨í”„

def listen_print_loop(client, streaming_config, stream):
    global last_command, test_completed, last_command_time, last_preview_key

    while True:
        audio_generator = stream.generator()
        requests_gen = (
            speech.StreamingRecognizeRequest(audio_content=content)
            for content in audio_generator
        )
        responses = client.streaming_recognize(streaming_config, requests_gen)

        try:
            for response in responses:
                if not response.results:
                    continue
                result = response.results[0]
                if not result.alternatives:
                    continue
                transcript = result.alternatives[0].transcript.strip()
                if transcript == "" or not result.is_final:
                    continue

                print(f"ğŸ¤ ì¸ì‹: {transcript}", flush=True)

                if not test_completed:
                    if normalize_command(transcript) == "test":
                        print("ğŸŸ¢ STT ì•ˆì •í™” ì™„ë£Œ. ëª…ë ¹ì–´ ì¸ì‹ì„ ì‹œì‘í•©ë‹ˆë‹¤.", flush=True)
                        test_completed = True
                    continue

                raw_words = transcript.lower().split()
                normalized_words = [normalize_command(word) for word in raw_words if word.strip()]
                phrases = remove_consecutive_duplicates(normalized_words)

                current_time = time.time()

                for command in phrases:
                    if command == "stop":
                        print("ğŸ‘‹ ì¢…ë£Œ ëª…ë ¹ ìˆ˜ì‹ ", flush=True)
                        return

                    if command.endswith("cut") and command != "cut":
                        key = command.replace("cut", "")
                        if key in INPUT_MAP:
                            direct_cut(key)
                            last_command = command
                            last_command_time = current_time
                        else:
                            print(f"ğŸ¤– ì¸ì‹ ì‹¤íŒ¨: {transcript}", flush=True)
                        continue

                    if command in INPUT_MAP:
                        preview_input(command)
                        last_command = command
                        last_command_time = current_time
                        continue

                    if command == "cut":
                        if last_preview_key:
                            cut()
                            print(f"âš¡ DIRECT CUT â†’ {last_preview_key} ({INPUT_MAP[last_preview_key]})", flush=True)
                        else:
                            print("âš ï¸ CUT ëª…ë ¹ì´ ì¸ì‹ë˜ì—ˆì§€ë§Œ, ì‚¬ì „ PREVIEW ëŒ€ìƒì´ ì—†ìŠµë‹ˆë‹¤.", flush=True)
                        last_command = command
                        last_command_time = current_time
                        continue

                    if command == "mix":
                        mix()
                        last_command = command
                        last_command_time = current_time
                        continue

                    print(f"ğŸ¤– ì¸ì‹ ì‹¤íŒ¨: {transcript}", flush=True)

        except Exception as e:
            print(f"âš ï¸ ì„¸ì…˜ ì˜¤ë¥˜ ë°œìƒ: {e}\nğŸ”„ STT ì„¸ì…˜ì„ ì¬ì‹œì‘í•©ë‹ˆë‹¤...", flush=True)
            while not stream._buff.empty():
                try:
                    stream._buff.get_nowait()
                except queue.Empty:
                    break
            time.sleep(1)
            continue

# â±ï¸ STT ì´ˆê¸°í™” íƒ€ì´ë¨¸

def console_timer():
    print("AI ìŠ¤ìœ„ì³ 'ëŒ€í˜¸ì•¼'ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. (í…ŒìŠ¤íŠ¸ ëª¨ë“œ)", flush=True)
    print("ğŸ™ï¸ 'TEST'ë¼ê³  ë§í•˜ì„¸ìš”.", flush=True)

# ğŸš€ ë©”ì¸ ì‹¤í–‰

def main():
    threading.Thread(target=console_timer).start()

    client = speech.SpeechClient()
    config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
        sample_rate_hertz=RATE,
        language_code="en-US"
    )
    streaming_config = speech.StreamingRecognitionConfig(
        config=config,
        interim_results=False,
    )

    with MicrophoneStream(RATE, CHUNK) as stream:
        listen_print_loop(client, streaming_config, stream)

if __name__ == "__main__":
    main()
